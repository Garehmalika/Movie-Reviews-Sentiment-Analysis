{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des bibliothèques nécessaires**"
      ],
      "metadata": {
        "id": "EMzivOUQzENH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HDJAMg-K5CS3"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "import pickle\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploration des données**"
      ],
      "metadata": {
        "id": "GcPuJkwPzJ1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "F5PXtjyjwKPU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s39V5de5wTKz",
        "outputId": "056e04e6-e0a6-4aa1-ae72-53dd74d7d5dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33559954-c43a-4186-b417-a81c29d5d25c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33559954-c43a-4186-b417-a81c29d5d25c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33559954-c43a-4186-b417-a81c29d5d25c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33559954-c43a-4186-b417-a81c29d5d25c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a03a7e4-db0d-44a5-9682-d60db38ddb65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a03a7e4-db0d-44a5-9682-d60db38ddb65')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a03a7e4-db0d-44a5-9682-d60db38ddb65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 68314,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49605,\n        \"samples\": [\n          \"I have seen this film 3 times. Mostly because I kept thinking while watching it, \\\"have I missed something here?\\\". Is there some reason this film was made? Was it trying to say something and I just missed it? Well after 3 viewings I failed to come up with an answer.<br /><br />I guess the worst thing I can say about any film is that it bored me, and I did not finish it. I will admit there is plenty of eye candy and fast editing and hip music to keep my attention all the way through but is that all a movie should be? <br /><br />I am not against extreme violence, it is almost non-stop, but it seems there should be some sort of inspiration. Something that is highlighted by it. The word gratuitous comes to mind but it is worse then that somehow. In the first part of the film we are all given insights into the motivations of the characters. And yes the 3 principles are very good in their roles. But the roles are completely unbelievable. So in the first part we get to know the characters, and in the second part most of em die and use sadistic glee in killing others. That seems to be the whole movie. And the first part has nothing to do with the second.<br /><br />For example. How could a nice smart guy like Zed agree to join a bunch of junkies and amateurs to do a job like this? It makes no sense. He is portrayed as smart, yet he goes ahead with this suicide mission. The fact that he survives is totally inconsistent with the rest of the hyper-real violence and mayhem. So what are we watching here a Hollywood romance with a happy ending or a super real, super violent blood bath? I recall having the same reaction to two other films this director was involved with: True Romance and Reservior Dogs.<br /><br />Needless dreck!\",\n          \"Chris Morris' Brass Eye TV series had always generated a large number of complaints, both from the audience and from the people taking part. But, nothing he has done has managed to stir up more controversy than this. The 2001 Brass Eye Special. Before the hugely overrated Jerry Springer Opera arrived, the Brass Eye Special held the record for the most complaints received about any TV program ever aired.<br /><br />The sheer volume of complaints that the general public made towards the Brass Eye Special was unbelievable! Many complaints were voiced by people who never even watched the program! The subject that the program handled turned many heads, but the message was widely misinterpreted. The message was even lost on some who enjoyed the program. This was not a show that mocked the subject of paedophilia. The show was purely about the media and it's presentation of the subject. Morris, is and always will be, a media satirist. The notion that the program 'makes fun' of paedophiles and children who have been abused is completely laughable! Morris never attempts to do either such thing. He merely draws our attention to the overwhelming, and very often stupid media hype surrounding the subject.<br /><br />Using many of his established 'Brass Eye' characters, such as, Ted Maul and others, Morris shows just how much the media over blow every little thing about a subject that they themselves created and built up, and the result is as funny, if not funnier, than anything Morris has done previously. Using his tried and tested formula, Morris manages to trick several gullible celebrities into believing that they are working on a serious documentary. In actuality, they are made to look like exactly what they are. Retards.<br /><br />All in all, the Brass Eye Special needs to be seen to be believed. And, with one opening line, Morris manages to sum up the entire media situation as it stood in 2001: \\\"Welcome to Paedo-Gedden!\\\"\",\n          \"Duck_of_Death needs to watch this film again, as his major criticism is completely baseless. The film never once forgot about the time delay, and it was mentioned explicitly in a couple of places. The crew were never shown having conversations with mission control that didn't obey the time delay rules.<br /><br />One thing I did think was a bit far-fetched was the amount of risk involved - would a crew land on a planet on which pressure suits would only last two hours? I doubt it. Would a manned space ship go into a star's corona? I doubt it. Would humans land on a moon that was being bombarded with huge amounts of radiation? I doubt it. Also, the ship seemed overly sturdy. Would a ship designed like that risk atmospheric flight to slow it down? I doubt it. Would it survive being hit by comet debris? I doubt it. I think in both cases the stresses on the structure would be too much. But all-in-all, the unlikely scenarios were compensated by some nicely done special effects, good editing and production, and some good acting, especially by the actors portraying the ship's commander and the Russian cosmonaut.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Rows: {dataset.shape[1]}\\nColumns: {dataset.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o3zr0GfwcuC",
        "outputId": "3f7b44d3-4ffe-4dbf-994e-f85a353b18d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 2\n",
            "Columns: 68314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Columns Names: {list(dataset.columns)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6vJDZrYwg9S",
        "outputId": "2ecd79ad-0586-4577-bb12-3ed9ddb7605a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns Names: ['review', 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()\n",
        "stopwords = list(STOP_WORDS)\n",
        "punctuations = string.punctuation"
      ],
      "metadata": {
        "id": "DEsEN-qkwoNg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentence):\n",
        "    mytokens = nlp(sentence)\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
        "    return mytokens"
      ],
      "metadata": {
        "id": "l4F0-qyAwszK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation and Vectorization**"
      ],
      "metadata": {
        "id": "qMb_TC47ww45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [clean_text(text) for text in X]\n",
        "    def fit(self, X, y, **fit_params):\n",
        "        return self\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text\n",
        "def clean_text(text):\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "_xoKBJw1w1H9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,1))\n",
        "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "XbAQ70rCw-xE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['review']\n",
        "y = dataset['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)"
      ],
      "metadata": {
        "id": "63DKOnu4xCt1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4EgU40Byydn",
        "outputId": "86ad443c-74c7-4302-b391-00b364e7f2c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54858    I love this show. My girlfriend was gonna get ...\n",
            "38064    You'll probably never see it, but the uncut ve...\n",
            "31112    This was quite possibly the worst movie I have...\n",
            "13725    In a movie that follows a struggling actor, pl...\n",
            "34159    Without a doubt, 12 MONKEYS is one of the best...\n",
            "Name: review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifie si certains documents sont vides après nettoyage\n",
        "print(X_train.isnull().sum())  # Vérifie les valeurs nulles\n",
        "print(X_train.str.len().describe())  # Vérifie la longueur des textes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdAOoZXGzALI",
        "outputId": "dacdf887-e753-4f25-c657-e80d861a36a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "count    54651.000000\n",
            "mean      1307.500595\n",
            "std        984.739663\n",
            "min         32.000000\n",
            "25%        699.000000\n",
            "50%        971.000000\n",
            "75%       1591.000000\n",
            "max      13704.000000\n",
            "Name: review, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictors():\n",
        "    def clean_text(text):\n",
        "        # Nettoyage de base, convertir en minuscules et enlever la ponctuation\n",
        "        text = text.lower()\n",
        "        text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
        "        return text\n",
        "    return clean_text\n"
      ],
      "metadata": {
        "id": "fNS7GbpFzILf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TextCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        # No fitting needed for text cleaning, so just return self\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Apply your cleaning function to each text entry\n",
        "        return [clean_text(text) for text in X]  # Assuming clean_text is your cleaning function\n"
      ],
      "metadata": {
        "id": "AuUBVXzN0kxq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "# Custom text cleaner transformer\n",
        "class TextCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [clean_text(text) for text in X]\n",
        "\n",
        "# Define the text cleaning function\n",
        "def clean_text(text):\n",
        "    # Example cleaning steps\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.strip()  # Remove leading/trailing whitespace\n",
        "    return text\n",
        "\n",
        "# Define your vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Set up the classifier and pipeline\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "LRmodel = Pipeline([\n",
        "    (\"cleaner\", TextCleaner()),  # Use the custom text cleaner\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "# Check if there are any empty documents in the training or test sets\n",
        "print(f'Number of empty documents in X_train: {sum([len(doc) == 0 for doc in X_train])}')\n",
        "print(f'Number of empty documents in X_test: {sum([len(doc) == 0 for doc in X_test])}')\n",
        "\n",
        "# Remove empty documents if there are any\n",
        "X_train = [doc for doc in X_train if len(doc) > 0]\n",
        "X_test = [doc for doc in X_test if len(doc) > 0]\n",
        "\n",
        "# Train the Model\n",
        "LRmodel.fit(X_train, y_train)\n",
        "LRpred = LRmodel.predict(X_test)\n",
        "\n",
        "# Print evaluation results\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, LRpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test, LRpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test, LRpred) * 100}%')\n",
        "\n",
        "# Save the model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_vCMlY2Jpn",
        "outputId": "6113f4c7-1510-43f5-bb8c-2bb1d2d046dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty documents in X_train: 0\n",
            "Number of empty documents in X_test: 0\n",
            "Confusion Matrix:\n",
            "[[6202  666]\n",
            " [ 520 6275]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.92      0.90      0.91      6868\n",
            "    positive       0.90      0.92      0.91      6795\n",
            "\n",
            "    accuracy                           0.91     13663\n",
            "   macro avg       0.91      0.91      0.91     13663\n",
            "weighted avg       0.91      0.91      0.91     13663\n",
            "\n",
            "Accuracy: 91.31962233770035%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/saved_model', exist_ok=True)\n",
        "\n",
        "# Now save the model\n",
        "pickle.dump(LRmodel, open('/saved_model/LinearRegression_model.sav', 'wb'))\n",
        "print('Logistic Regression trained Model Saved')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTIFokN-4Wne",
        "outputId": "d321abc6-af29-47ba-a085-6e4cebcab068"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression trained Model Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "uisiCCDCyIff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.datasets import imdb\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Padding des séquences pour avoir une longueur uniforme\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "# Création du modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=200))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Prédiction sur les données de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Conversion des prédictions en classes (0 ou 1)\n",
        "y_pred = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Calcul des métriques\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0NcHnoAyHZh",
        "outputId": "cc4f289d-edc8-4f15-a215-b626cba3f568"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 845ms/step - accuracy: 0.7023 - loss: 0.5508 - val_accuracy: 0.8206 - val_loss: 0.4053\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 811ms/step - accuracy: 0.8641 - loss: 0.3301 - val_accuracy: 0.8470 - val_loss: 0.3613\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 814ms/step - accuracy: 0.8932 - loss: 0.2715 - val_accuracy: 0.8493 - val_loss: 0.4116\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 816ms/step - accuracy: 0.9010 - loss: 0.2536 - val_accuracy: 0.8499 - val_loss: 0.3711\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 812ms/step - accuracy: 0.9050 - loss: 0.2423 - val_accuracy: 0.8377 - val_loss: 0.4136\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step\n",
            "Accuracy: 0.8377\n",
            "Precision: 0.8731\n",
            "Recall: 0.7903\n",
            "F1-Score: 0.8296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LinearSVC**"
      ],
      "metadata": {
        "id": "SP4dTvwK0Tqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Préparation des données\n",
        "X = dataset['review']\n",
        "y = dataset['sentiment']\n",
        "\n",
        "# Division train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)\n",
        "\n",
        "# Vérification des dimensions\n",
        "print(\"Dimensions initiales:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "\n",
        "# Création d'une classe transformateur personnalisée\n",
        "class TextCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        cleaned_text = []\n",
        "        for text in X:\n",
        "            # Si vous aviez une fonction de nettoyage précédente, insérez-la ici\n",
        "            cleaned_text.append(text)\n",
        "        return cleaned_text\n",
        "\n",
        "# Création du pipeline\n",
        "SVCclassifier = LinearSVC(random_state=77)\n",
        "SVCmodel = Pipeline([\n",
        "    (\"cleaner\", TextCleaner()),\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', SVCclassifier)\n",
        "])\n",
        "\n",
        "# Entraînement du modèle\n",
        "SVCmodel.fit(X_train, y_train)\n",
        "\n",
        "# Prédictions\n",
        "SVCpred = SVCmodel.predict(X_test)\n",
        "\n",
        "# Affichage des métriques\n",
        "print(\"\\nRésultats:\")\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test,SVCpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test,SVCpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test,SVCpred)*100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1czj_SvoHY1I",
        "outputId": "c1e1a3d4-e50d-4d37-ff46-e2a1b69683c1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions initiales:\n",
            "X_train: (54651,)\n",
            "y_train: (54651,)\n",
            "\n",
            "Résultats:\n",
            "Confusion Matrix:\n",
            "[[6397  471]\n",
            " [ 418 6377]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.94      0.93      0.94      6868\n",
            "    positive       0.93      0.94      0.93      6795\n",
            "\n",
            "    accuracy                           0.93     13663\n",
            "   macro avg       0.93      0.93      0.93     13663\n",
            "weighted avg       0.93      0.93      0.93     13663\n",
            "\n",
            "Accuracy: 93.49%\n"
          ]
        }
      ]
    }
  ]
}